#resove the issue with not predicting 0 class
#X_train, X_test, y_train, y_test = train_test_split(
#    X, y, test_size=0.2, 
#    random_state=42, 
#    stratify=y
#)

#from sklearn.preprocessing import StandardScaler
#scaler = StandardScaler()
#X_train = scaler.fit_transform(X_train)
#X_test  = scaler.transform(X_test)


param_grid = {
    # various depths & widths
    'hidden_layer_sizes': [
        (50,), (100,), (50, 25), (100, 50),
        (150,100,50), (120,80,40), (100,50,30),
        (200,100,50,25), (100,100,50,25)
    ],

    # all supported activations
    'activation': ['identity', 'logistic','tanh','relu'],

    # solvers (lbfgs only for small data)
    'solver': ['sgd','adam','lbfgs'],

    # for sgd
    'learning_rate': ['constant','invscaling','adaptive'],
    'learning_rate_init': [0.001, 0.01, 0.1, 1],

    # regularization
    'alpha': [1e-5, 1e-4, 1e-3, 1e-2, 0.05, 0.1, 1],

    # momentum & Nesterov (only used with solver='sgd')
    'momentum': [0.5, 0.9],
    'nesterovs_momentum': [True, False],

    # how many samples per minibatch
    'batch_size': [16, 32, 64, 128, 'auto'],

    # stopping criteria
    'tol': [1e-4, 1e-3, 1e-2],
    'early_stopping': [True, False],
    'validation_fraction': [0.1, 0.2, 0.3],
    'n_iter_no_change': [5, 10, 20],

    # adam‚Äêspecific
    'beta_1': [0.85, 0.9, 0.95],
    'beta_2': [0.999, 0.9995, 0.9999],
    'epsilon': [1e-8, 1e-7, 1e-6],
    
    # maximum epochs
    'max_iter': [100, 200, 300, 400, 500, 600]
}